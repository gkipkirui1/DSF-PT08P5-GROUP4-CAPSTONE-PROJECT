{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I have used CRISP-DM framework in its data science process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Overview\n",
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BUSINESS UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The audience\n",
    "\n",
    "The Target audience for this project are:\n",
    "* xx\n",
    "\n",
    "* xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Business Problem\n",
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Business Objectives\n",
    "The objective of this project is to develop a model to:\n",
    "* Come up with a xx\n",
    "\n",
    "* xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Metrics of success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xxx\n",
    "\n",
    "xx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Data Source\n",
    "\n",
    "The data was sourced from https://www.kaggle.com/datasets/marusagar/bank-transaction-fraud-detection \n",
    "===\n",
    "\n",
    " for amendment: The dataset contains detailed information about bank transactions for customers of LOL Bank Pvt. Ltd., with the objective of detecting fraudulent activities. It includes customer demographic details (e.g., Customer ID, Name, Gender, Age, State, and City), transaction specifics (e.g., Transaction ID, Date, Amount, Type, Merchant, Device, and Location), as well as account and bank details (e.g., Account Balance, Account Type, Branch). Additionally, it flags whether a transaction is fraudulent or not. This dataset is used to build and train models to identify fraudulent transactions based on patterns, ensuring secure banking practices.\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DATA UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Description and Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset -  I will load the dataset into a pandas DataFrame which will facilitate easy manipulation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/archive.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(extracted_files_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Extract the zip file\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(zip_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[0;32m     13\u001b[0m     zip_ref\u001b[38;5;241m.\u001b[39mextractall(extracted_files_path)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles extracted to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextracted_files_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\zipfile\\__init__.py:1331\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1331\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mopen(file, filemode)\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/archive.zip'"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to your zip file\n",
    "zip_file_path = 'data/archive.zip'\n",
    "extracted_files_path = 'data'\n",
    "\n",
    "# Make sure the output directory exists\n",
    "os.makedirs(extracted_files_path, exist_ok=True)\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_files_path)\n",
    "\n",
    "print(f\"Files extracted to {extracted_files_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df:\n",
      "                            Customer_ID        Customer_Name  Gender  Age  \\\n",
      "0  d5f6ec07-d69e-4f47-b9b4-7c58ff17c19e           Osha Tella    Male   60   \n",
      "1  7c14ad51-781a-4db9-b7bd-67439c175262      Hredhaan Khosla  Female   51   \n",
      "2  3a73a0e5-d4da-45aa-85f3-528413900a35       Ekani Nazareth    Male   20   \n",
      "3  7902f4ef-9050-4a79-857d-9c2ea3181940  Yamini Ramachandran  Female   57   \n",
      "4  3a4bba70-d9a9-4c5f-8b92-1735fd8c19e9         Kritika Rege  Female   43   \n",
      "\n",
      "         State                City                Bank_Branch Account_Type  \\\n",
      "0       Kerala  Thiruvananthapuram  Thiruvananthapuram Branch      Savings   \n",
      "1  Maharashtra              Nashik              Nashik Branch     Business   \n",
      "2        Bihar           Bhagalpur           Bhagalpur Branch      Savings   \n",
      "3   Tamil Nadu             Chennai             Chennai Branch     Business   \n",
      "4       Punjab            Amritsar            Amritsar Branch      Savings   \n",
      "\n",
      "                         Transaction_ID Transaction_Date  ...  \\\n",
      "0  4fa3208f-9e23-42dc-b330-844829d0c12c       23-01-2025  ...   \n",
      "1  c9de0c06-2c4c-40a9-97ed-3c7b8f97c79c       11-01-2025  ...   \n",
      "2  e41c55f9-c016-4ff3-872b-cae72467c75c       25-01-2025  ...   \n",
      "3  7f7ee11b-ff2c-45a3-802a-49bc47c02ecb       19-01-2025  ...   \n",
      "4  f8e6ac6f-81a1-4985-bf12-f60967d852ef       30-01-2025  ...   \n",
      "\n",
      "  Merchant_Category  Account_Balance Transaction_Device  \\\n",
      "0        Restaurant         74557.27    Voice Assistant   \n",
      "1        Restaurant         74622.66  POS Mobile Device   \n",
      "2         Groceries         66817.99                ATM   \n",
      "3     Entertainment         58177.08     POS Mobile App   \n",
      "4     Entertainment         16108.56       Virtual Card   \n",
      "\n",
      "         Transaction_Location Device_Type  Is_Fraud Transaction_Currency  \\\n",
      "0  Thiruvananthapuram, Kerala         POS         0                  INR   \n",
      "1         Nashik, Maharashtra     Desktop         0                  INR   \n",
      "2            Bhagalpur, Bihar     Desktop         0                  INR   \n",
      "3         Chennai, Tamil Nadu      Mobile         0                  INR   \n",
      "4            Amritsar, Punjab      Mobile         0                  INR   \n",
      "\n",
      "  Customer_Contact Transaction_Description           Customer_Email  \n",
      "0   +9198579XXXXXX     Bitcoin transaction      oshaXXXXX@XXXXX.com  \n",
      "1   +9191074XXXXXX        Grocery delivery  hredhaanXXXX@XXXXXX.com  \n",
      "2   +9197745XXXXXX  Mutual fund investment      ekaniXXX@XXXXXX.com  \n",
      "3   +9195889XXXXXX           Food delivery  yaminiXXXXX@XXXXXXX.com  \n",
      "4   +9195316XXXXXX          Debt repayment   kritikaXXXX@XXXXXX.com  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into dataframes\n",
    "df= pd.read_csv('data/Bank_Transaction_Fraud_Detection.csv')\n",
    "\n",
    "# Display the first five rows of the dataframe\n",
    "print(\"df:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I made steps to understand the dataset before moving on to the data cleaning and transformation phases. The steps include reviewing the structure and the content of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (200000, 24)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(\"df shape:\", df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checked the information of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   Customer_ID              200000 non-null  object \n",
      " 1   Customer_Name            200000 non-null  object \n",
      " 2   Gender                   200000 non-null  object \n",
      " 3   Age                      200000 non-null  int64  \n",
      " 4   State                    200000 non-null  object \n",
      " 5   City                     200000 non-null  object \n",
      " 6   Bank_Branch              200000 non-null  object \n",
      " 7   Account_Type             200000 non-null  object \n",
      " 8   Transaction_ID           200000 non-null  object \n",
      " 9   Transaction_Date         200000 non-null  object \n",
      " 10  Transaction_Time         200000 non-null  object \n",
      " 11  Transaction_Amount       200000 non-null  float64\n",
      " 12  Merchant_ID              200000 non-null  object \n",
      " 13  Transaction_Type         200000 non-null  object \n",
      " 14  Merchant_Category        200000 non-null  object \n",
      " 15  Account_Balance          200000 non-null  float64\n",
      " 16  Transaction_Device       200000 non-null  object \n",
      " 17  Transaction_Location     200000 non-null  object \n",
      " 18  Device_Type              200000 non-null  object \n",
      " 19  Is_Fraud                 200000 non-null  int64  \n",
      " 20  Transaction_Currency     200000 non-null  object \n",
      " 21  Customer_Contact         200000 non-null  object \n",
      " 22  Transaction_Description  200000 non-null  object \n",
      " 23  Customer_Email           200000 non-null  object \n",
      "dtypes: float64(2), int64(2), object(20)\n",
      "memory usage: 36.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Extract information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thexx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renamed columns with appended suffix after merging datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checked the shape of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used isna() to check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer_ID                0\n",
       "Customer_Name              0\n",
       "Gender                     0\n",
       "Age                        0\n",
       "State                      0\n",
       "City                       0\n",
       "Bank_Branch                0\n",
       "Account_Type               0\n",
       "Transaction_ID             0\n",
       "Transaction_Date           0\n",
       "Transaction_Time           0\n",
       "Transaction_Amount         0\n",
       "Merchant_ID                0\n",
       "Transaction_Type           0\n",
       "Merchant_Category          0\n",
       "Account_Balance            0\n",
       "Transaction_Device         0\n",
       "Transaction_Location       0\n",
       "Device_Type                0\n",
       "Is_Fraud                   0\n",
       "Transaction_Currency       0\n",
       "Customer_Contact           0\n",
       "Transaction_Description    0\n",
       "Customer_Email             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I checked for duplicate rows to enable me clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 24 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Customer_ID              0 non-null      object \n",
      " 1   Customer_Name            0 non-null      object \n",
      " 2   Gender                   0 non-null      object \n",
      " 3   Age                      0 non-null      int64  \n",
      " 4   State                    0 non-null      object \n",
      " 5   City                     0 non-null      object \n",
      " 6   Bank_Branch              0 non-null      object \n",
      " 7   Account_Type             0 non-null      object \n",
      " 8   Transaction_ID           0 non-null      object \n",
      " 9   Transaction_Date         0 non-null      object \n",
      " 10  Transaction_Time         0 non-null      object \n",
      " 11  Transaction_Amount       0 non-null      float64\n",
      " 12  Merchant_ID              0 non-null      object \n",
      " 13  Transaction_Type         0 non-null      object \n",
      " 14  Merchant_Category        0 non-null      object \n",
      " 15  Account_Balance          0 non-null      float64\n",
      " 16  Transaction_Device       0 non-null      object \n",
      " 17  Transaction_Location     0 non-null      object \n",
      " 18  Device_Type              0 non-null      object \n",
      " 19  Is_Fraud                 0 non-null      int64  \n",
      " 20  Transaction_Currency     0 non-null      object \n",
      " 21  Customer_Contact         0 non-null      object \n",
      " 22  Transaction_Description  0 non-null      object \n",
      " 23  Customer_Email           0 non-null      object \n",
      "dtypes: float64(2), int64(2), object(20)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df[df.duplicated()]\n",
    "print(\"Duplicate Rows:\")\n",
    "duplicates.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove duplicate rows\n",
    "# df_final = df.drop_duplicates()\n",
    "# df_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating summary statistics will help get insights on the dataset distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Transaction_Amount</th>\n",
       "      <th>Account_Balance</th>\n",
       "      <th>Is_Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.015110</td>\n",
       "      <td>49538.015554</td>\n",
       "      <td>52437.988784</td>\n",
       "      <td>0.050440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.288774</td>\n",
       "      <td>28551.874004</td>\n",
       "      <td>27399.507128</td>\n",
       "      <td>0.218852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.290000</td>\n",
       "      <td>5000.820000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>24851.345000</td>\n",
       "      <td>28742.395000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>49502.440000</td>\n",
       "      <td>52372.555000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>74314.625000</td>\n",
       "      <td>76147.670000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>98999.980000</td>\n",
       "      <td>99999.950000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age  Transaction_Amount  Account_Balance       Is_Fraud\n",
       "count  200000.000000       200000.000000    200000.000000  200000.000000\n",
       "mean       44.015110        49538.015554     52437.988784       0.050440\n",
       "std        15.288774        28551.874004     27399.507128       0.218852\n",
       "min        18.000000           10.290000      5000.820000       0.000000\n",
       "25%        31.000000        24851.345000     28742.395000       0.000000\n",
       "50%        44.000000        49502.440000     52372.555000       0.000000\n",
       "75%        57.000000        74314.625000     76147.670000       0.000000\n",
       "max        70.000000        98999.980000     99999.950000       1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary statistics \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The average xx\n",
    "\n",
    "* The dataset xx unique identifier.\n",
    "\n",
    "* xxx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ascertain xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I prepared data in a format compatible with surprise by use of a reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MODELLING & EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the best model \n",
    "\n",
    "xx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xxx model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. xx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. xx Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Accuracy\n",
    "* xx\n",
    "\n",
    "\n",
    "### xx\n",
    "* xx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* xx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights for next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* xx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
